# Pipeline MLOps para Modelo em ProduÃ§Ã£o

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![MLflow](https://img.shields.io/badge/MLflow-2.22.1-orange.svg)](https://mlflow.org/)
[![Kubeflow](https://img.shields.io/badge/Kubeflow-2.0.0-blue.svg)](https://www.kubeflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Este projeto implementa um pipeline MLOps completo para detecÃ§Ã£o de fraude em transaÃ§Ãµes financeiras, incluindo treinamento, experimentaÃ§Ã£o, versionamento e deploy do modelo.

## Estrutura do Projeto

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Dados brutos
â”‚   â””â”€â”€ processed/     # Dados processados
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/         # Scripts de processamento de dados
â”‚   â”œâ”€â”€ training/     # Scripts de treinamento
â”‚   â”œâ”€â”€ api/          # API para servir o modelo
â”‚   â””â”€â”€ serve.py      # Script Python para servir o modelo com Flask
â”œâ”€â”€ models/           # Modelos salvos (ignorados pelo git)
â”œâ”€â”€ tests/            # Testes unitÃ¡rios (incluindo test_prediction.py)
â”œâ”€â”€ Dockerfile        # ConfiguraÃ§Ã£o do container
â””â”€â”€ requirements.txt  # DependÃªncias do projeto
```

## ConfiguraÃ§Ã£o do Ambiente

### PrÃ©-requisitos
- Python 3.8+
- Docker Desktop
- Minikube
- kubectl

### InstalaÃ§Ã£o das DependÃªncias
```bash
pip install -r requirements.txt
```

## ConfiguraÃ§Ã£o do MLflow no Kubernetes

### 1. Iniciar o Minikube
```powershell
# Abra o PowerShell como administrador
cd "C:\Pipeline MLOps para Modelo em Producao"
minikube start --driver=docker --memory=3000 --cpus=4
```

### 2. Aplicar a ConfiguraÃ§Ã£o do MLflow
```powershell
kubectl apply -f mlflow-deployment.yaml
```

### 3. Verificar o Status do Pod
```powershell
kubectl get pods
# Aguarde atÃ© ver o status "Running"
```

### 4. Acessar a Interface do MLflow
```powershell
minikube service mlflow --url
```
Copie o endereÃ§o retornado e cole no seu navegador.

**Importante:** Mantenha o terminal aberto enquanto estiver usando o MLflow.

## Treinamento do Modelo

### 1. Preparar os Dados
```powershell
python src/data/download_data.py
```

### 2. Treinar o Modelo
```powershell
python src/train.py
```

O script irÃ¡:
- Realizar validaÃ§Ã£o cruzada
- Testar diferentes configuraÃ§Ãµes de hiperparÃ¢metros
- Registrar mÃ©tricas, parÃ¢metros e artefatos (incluindo matriz de confusÃ£o) no MLflow
- Salvar o melhor modelo localmente e no MLflow Model Registry

## AnÃ¡lise de Experimentos e DecisÃ£o do Modelo (MLflow UI)

ApÃ³s o treinamento, acesse a interface do MLflow para visualizar os experimentos e as mÃ©tricas de cada configuraÃ§Ã£o:

```powershell
mlflow ui --port 51099 --backend-store-uri sqlite:///mlruns/mlflow.db --default-artifact-root mlruns
```
Abra no navegador: `http://127.0.0.1:51099`

Na UI do MLflow, vocÃª poderÃ¡:
- Comparar os runs e as mÃ©tricas de cada configuraÃ§Ã£o.
- Visualizar os parÃ¢metros usados em cada treinamento.
- Analisar a matriz de confusÃ£o gerada e salva como artefato para cada run.
- **ExplicaÃ§Ã£o da DecisÃ£o:** Demonstre como a "ConfiguraÃ§Ã£o 2" (ou a configuraÃ§Ã£o com o melhor F1-Score/balanceamento entre precisÃ£o e recall, dependendo do seu foco) foi selecionada como o "melhor modelo" com base nas mÃ©tricas de teste (especialmente o F1-Score, que Ã© crucial para problemas de classificaÃ§Ã£o desbalanceada como fraude). Mostre os detalhes do run escolhido, seus parÃ¢metros, mÃ©tricas e artefatos.

## Deploy Local do Modelo (API com Flask)

Para disponibilizar o modelo para inferÃªncia, usaremos um servidor Flask simples que carrega o modelo salvo.

### 1. Iniciar o Servidor Flask
Certifique-se de que o servidor Flask estÃ¡ rodando. Se o servidor MLflow UI estiver em execuÃ§Ã£o em outro terminal, abra um **novo terminal** e execute:

```powershell
python -m src.serve
```
O servidor estarÃ¡ disponÃ­vel em `http://localhost:5001`.

### 2. Exemplo de Uso da API

Crie um arquivo `input.json` no diretÃ³rio raiz do seu projeto com os dados de entrada para o modelo (o formato esperado Ã© `dataframe_split` conforme utilizado pelo MLflow Serving):

```json
{
  "dataframe_split": {
    "columns": [
      "V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10",
      "V11", "V12", "V13", "V14", "V15", "V16", "V17", "V18", "V19", "V20",
      "V21", "V22", "V23", "V24", "V25", "V26", "V27", "V28", "Amount"
    ],
    "data": [
      [
        -0.42861348, 0.95758079, 0.40794421, 0.4437166, -0.06109918,
        -0.12932631, 0.49071077, 0.15858054, -0.27967918, -0.45789647,
        -0.24430485, 0.15082159, -0.06316279, -0.23118944, -0.19946896,
        -0.09459392, -0.10804705, -0.03848293, -0.01548058, 0.05286548,
        -0.10091398, -0.20786938, -0.27503713, -0.20239077, 0.28786937,
        0.12467389, 0.06312458, 0.06312458, 10.00
      ]
    ]
  }
}
```

EntÃ£o, use o PowerShell para enviar uma requisiÃ§Ã£o POST:

```powershell
Invoke-RestMethod -Uri http://localhost:5001/predict -Method Post -ContentType "application/json" -InFile input.json
```

A resposta da API serÃ¡ a prediÃ§Ã£o do modelo (0 para nÃ£o fraude, 1 para fraude).

## Monitoramento

O MLflow fornece:
- Rastreamento de experimentos
- MÃ©tricas de performance
- Versionamento de modelos
- ComparaÃ§Ã£o entre diferentes execuÃ§Ãµes

Acesse a interface web do MLflow para visualizar:
- GrÃ¡ficos de mÃ©tricas
- ImportÃ¢ncia das features
- ParÃ¢metros dos modelos
- Artefatos salvos

## PrÃ³ximos Passos

1. Implementar testes automatizados
2. Configurar CI/CD
3. Adicionar monitoramento de drift
4. Implementar retreinamento automÃ¡tico
5. Adicionar logging e alertas

## ğŸ¯ Objetivo

Criar um pipeline automatizado que:
- Treina modelos de ML de forma reprodutÃ­vel
- Versiona experimentos e modelos
- Faz deploy em ambiente Kubernetes
- Monitora performance em produÃ§Ã£o

## ğŸ—ï¸ Arquitetura

O pipeline Ã© composto por:

1. **PreparaÃ§Ã£o de Dados**
   - ETL com PySpark
   - PrÃ©-processamento
   - ValidaÃ§Ã£o de dados

2. **Treinamento**
   - Experimentos com MLflow
   - Modelos TensorFlow/PyTorch
   - Versionamento de artefatos

3. **Pipeline MLOps**
   - Kubeflow Pipelines
   - CI/CD com ArgoCD
   - GitOps para versionamento

4. **Deploy e Monitoramento**
   - Kubernetes
   - Kubeflow Serving
   - Monitoramento com Prometheus/Grafana

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                   # Dados brutos e processados (ignorados pelo git)
â”œâ”€â”€ notebooks/             # Jupyter notebooks para experimentaÃ§Ã£o
â”œâ”€â”€ src/                   # CÃ³digo fonte
â”‚   â”œâ”€â”€ data/             # Scripts de ETL
â”‚   â”œâ”€â”€ models/           # DefiniÃ§Ã£o dos modelos
â”‚   â”œâ”€â”€ training/         # Scripts de treinamento
â”‚   â””â”€â”€ serve.py          # CÃ³digo para servir o modelo com Flask
â”œâ”€â”€ pipeline/             # DefiniÃ§Ãµes do Kubeflow Pipeline
â”œâ”€â”€ k8s/                  # Manifests Kubernetes
â”œâ”€â”€ tests/                # Testes automatizados
â””â”€â”€ docker/               # Dockerfiles
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

- Python 3.12
- Docker
- Kubernetes cluster
- Kubeflow
- MLflow

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/mlops-pipeline.git
cd mlops-pipeline
```

2. Crie e ative o ambiente virtual:
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate # Linux/Mac
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Configure as variÃ¡veis de ambiente:
```bash
cp env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

### Executando o Pipeline

1. Inicie o MLflow:
```bash
mlflow server
```

2. Execute o pipeline:
```bash
python src/pipeline/run_pipeline.py
```

## ğŸ“Š Monitoramento

- MLflow UI: http://localhost:5000
- Grafana Dashboard: http://localhost:3000
- Prometheus: http://localhost:9090

## ğŸ§ª Testes

Execute os testes automatizados:
```bash
pytest tests/
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie sua branch de feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ“« Contato

Seu Nome - [@seu_twitter](https://twitter.com/seu_twitter) - email@exemplo.com

Link do Projeto: [https://github.com/seu-usuario/mlops-pipeline](https://github.com/seu-usuario/mlops-pipeline)

## ConfiguraÃ§Ã£o do Ambiente

### PrÃ©-requisitos
- Python 3.8+
- Docker Desktop
- Minikube
- kubectl

### InstalaÃ§Ã£o das DependÃªncias
```bash
pip install -r requirements.txt
```

## ConfiguraÃ§Ã£o do MLflow no Kubernetes

### 1. Iniciar o Minikube
```powershell
# Abra o PowerShell como administrador
cd "C:\Pipeline MLOps para Modelo em Producao"
minikube start --driver=docker --memory=3000 --cpus=4
```

### 2. Aplicar a ConfiguraÃ§Ã£o do MLflow
```powershell
kubectl apply -f mlflow-deployment.yaml
```

### 3. Verificar o Status do Pod
```powershell
kubectl get pods
# Aguarde atÃ© ver o status "Running"
```

### 4. Acessar a Interface do MLflow
```powershell
minikube service mlflow --url
```
Copie o endereÃ§o retornado (exemplo: http://127.0.0.1:52323) e cole no seu navegador.

**Importante:** Mantenha o terminal aberto enquanto estiver usando o MLflow, pois o serviÃ§o depende dele para continuar rodando. 